{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP09kJya+/Um4x46/lpybn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbalAzizLCWU/BSSE-DS-Project/blob/main/SunbalW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd-nXIZyDnv7",
        "outputId": "e6449a47-c1f1-4e48-a017-3c9ede72e390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Part 1: Setting up Kaggle and Downloading Dataset ---\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Kaggle API token installed.\n",
            "Dataset URL: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification\n",
            "License(s): copyright-authors\n",
            "Downloading garbage-classification.zip to /content\n",
            " 73% 60.0M/82.0M [00:00<00:00, 596MB/s]\n",
            "100% 82.0M/82.0M [00:00<00:00, 634MB/s]\n",
            "\n",
            "Dataset downloaded. Unzipping...\n",
            "Dataset unzipped. Ready for preprocessing.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Setup\n",
        "\n",
        "print(\"--- Part 1: Setting up Kaggle and Downloading Dataset ---\")\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "# (Ensure kaggle.json is uploaded to your Colab environment)\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "print(\"Kaggle API token installed.\")\n",
        "\n",
        "!kaggle datasets download -d asdasdasasdas/garbage-classification\n",
        "print(\"\\nDataset downloaded. Unzipping...\")\n",
        "\n",
        "!unzip -q garbage-classification.zip\n",
        "print(\"Dataset unzipped. Ready for preprocessing.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "\n",
        "print(\"\\n--- Part 2: Executing Week 5 Class Task (Linear Regression Demo) ---\")\n",
        "\n",
        "# Import libraries for the class task\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# 1. Loading the data\n",
        "diabetes = load_diabetes()\n",
        "X_diabetes = diabetes.data\n",
        "y_diabetes = diabetes.target\n",
        "\n",
        "# 2. Spliting the data\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_diabetes, y_diabetes, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Creating and train the model\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_train_lr, y_train_lr)\n",
        "\n",
        "# 4. Making predictions\n",
        "y_pred_lr = model_lr.predict(X_test_lr)\n",
        "\n",
        "# 5. Evaluating the model\n",
        "mae = mean_absolute_error(y_test_lr, y_pred_lr)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_lr, y_pred_lr))\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(\"Class Task (Linear Regression Demo) complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGmaf9s6FEH-",
        "outputId": "74e51bb3-eb8c-4aa1-9e74-b8c315901f8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 2: Executing Week 5 Class Task (Linear Regression Demo) ---\n",
            "Mean Absolute Error (MAE): 42.79\n",
            "Root Mean Squared Error (RMSE): 53.85\n",
            "Class Task (Linear Regression Demo) complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted Baseline Model\n",
        "\n",
        "print(\"\\n--- Part 3: Executing Week 5 Project Assignment (Baseline Classification Model) ---\")\n",
        "\n",
        "# Import libraries for the project assignment\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Defining Constants and Preprocessing Function ---\n",
        "\n",
        "# Defining constants\n",
        "data_dir = 'Garbage classification/Garbage classification'\n",
        "classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "IMG_SIZE = 64 # Resize images to 64x64 for a fast baseline\n",
        "\n",
        "# Lists to hold our data\n",
        "X_data = [] # This will hold the flattened image data\n",
        "y_data = [] # This will hold the labels\n",
        "\n",
        "def preprocess_images():\n",
        "    \"\"\"\n",
        "    Loops through all images, resizes them, flattens them,\n",
        "    and returns two numpy arrays: X (data) and y (labels).\n",
        "    \"\"\"\n",
        "    print(f\"\\nStarting image preprocessing from {data_dir}...\")\n",
        "    for class_name in classes:\n",
        "        class_dir_path = os.path.join(data_dir, class_name)\n",
        "        # Convert class name (e.g., 'paper') to a number (e.g., 3)\n",
        "        class_label = classes.index(class_name)\n",
        "\n",
        "        if not os.path.isdir(class_dir_path):\n",
        "            print(f\"Warning: Directory not found {class_dir_path}\")\n",
        "            continue\n",
        "\n",
        "        for image_file in os.listdir(class_dir_path):\n",
        "            image_path = os.path.join(class_dir_path, image_file)\n",
        "            try:\n",
        "                # Open image, convert to grayscale, and resize\n",
        "                img = Image.open(image_path).convert('L') # 'L' = grayscale\n",
        "                img_resized = img.resize((IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "                # Flatten the 64x64 image into a 1D vector of 4096 pixels\n",
        "                img_vector = np.array(img_resized).flatten()\n",
        "\n",
        "                X_data.append(img_vector)\n",
        "                y_data.append(class_label)\n",
        "\n",
        "            except Exception as e:\n",
        "                # Skip corrupted files [cite: 216-217, 621-622, 1081-1083]\n",
        "                print(f\"Skipping corrupted file: {image_path} | Error: {e}\")\n",
        "\n",
        "    print(\"Image preprocessing complete.\")\n",
        "    return np.array(X_data), np.array(y_data)\n",
        "\n",
        "# Loading, Preprocessing, and Scaling Data ---\n",
        "\n",
        "# Run the function\n",
        "X, y = preprocess_images()\n",
        "\n",
        "print(f\"\\nData shape (X): {X.shape}\") # Should be (2527, 4096)\n",
        "print(f\"Labels shape (y): {y.shape}\") # Should be (2527,)\n",
        "\n",
        "# Scale the data (very important for Logistic Regression)\n",
        "print(\"\\nScaling data (StandardScaler)...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Data scaling complete.\")\n",
        "\n",
        "# Train/Test Split ---\n",
        "print(\"\\nSplitting data into 80% train and 20% test sets...\")\n",
        "# We use stratify=y to ensure the class imbalance is preserved in both sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Training images: {X_train.shape[0]}\")\n",
        "print(f\"Testing images: {X_test.shape[0]}\")\n",
        "\n",
        "# Train Baseline Model (Logistic Regression) ---\n",
        "print(\"\\nTraining baseline model (Logistic Regression)...\")\n",
        "# We increase max_iter because 4096 features is a lot\n",
        "# This is our adapted model for the baseline *classification* task [cite: 582-583]\n",
        "baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Evaluate Baseline Model ---\n",
        "print(\"\\nEvaluating baseline model on the test set...\")\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Calculate Accuracy (the correct metric for classification)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"     Week 5 Assignment: Baseline Model Output\")\n",
        "print(\"=======================================================\")\n",
        "print(f\"Model: Logistic Regression (on {IMG_SIZE}x{IMG_SIZE} flattened pixels)\")\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print a detailed report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=classes))\n",
        "\n",
        "print(\"\\n--- Week 5 Tasks Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0o4_DGuFWQ9",
        "outputId": "9c266474-9f98-417a-f169-489ffa05fa3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 3: Executing Week 5 Project Assignment (Baseline Classification Model) ---\n",
            "\n",
            "Starting image preprocessing from Garbage classification/Garbage classification...\n",
            "Image preprocessing complete.\n",
            "\n",
            "Data shape (X): (2527, 4096)\n",
            "Labels shape (y): (2527,)\n",
            "\n",
            "Scaling data (StandardScaler)...\n",
            "Data scaling complete.\n",
            "\n",
            "Splitting data into 80% train and 20% test sets...\n",
            "Training images: 2021\n",
            "Testing images: 506\n",
            "\n",
            "Training baseline model (Logistic Regression)...\n",
            "Model training complete.\n",
            "\n",
            "Evaluating baseline model on the test set...\n",
            "\n",
            "=======================================================\n",
            "     Week 5 Assignment: Baseline Model Output\n",
            "=======================================================\n",
            "Model: Logistic Regression (on 64x64 flattened pixels)\n",
            "Test Accuracy: 31.42%\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.35      0.30      0.32        81\n",
            "       glass       0.26      0.26      0.26       100\n",
            "       metal       0.19      0.18      0.19        82\n",
            "       paper       0.50      0.46      0.48       119\n",
            "     plastic       0.30      0.33      0.31        97\n",
            "       trash       0.18      0.26      0.21        27\n",
            "\n",
            "    accuracy                           0.31       506\n",
            "   macro avg       0.29      0.30      0.29       506\n",
            "weighted avg       0.32      0.31      0.32       506\n",
            "\n",
            "\n",
            "--- Week 5 Tasks Complete ---\n"
          ]
        }
      ]
    }
  ]
}