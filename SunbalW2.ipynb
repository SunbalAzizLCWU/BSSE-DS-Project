{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyOjr+IpsXyZ19ThSpZL1wT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbalAzizLCWU/BSSE-DS-Project/blob/main/SunbalW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR32Vg-_lsVW",
        "outputId": "51e39acf-81fc-4421-f15a-ba7535a3cde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Kaggle API token installed.\n"
          ]
        }
      ],
      "source": [
        "# First We'll install the Kaggle library\n",
        "!pip install kaggle\n",
        "\n",
        "# Set up the Kaggle API token\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API token installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset\n",
        "# This is the \"Data Collection\" step\n",
        "# We are using the dataset from source kaggle.com\n",
        "!kaggle datasets download -d asdasdasasdas/garbage-classification\n",
        "print(\"\\nDataset downloaded. Unzipping...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boH0V-VWmWNM",
        "outputId": "ef1e4417-e477-4ad0-e421-6baf54cd29da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification\n",
            "License(s): copyright-authors\n",
            "garbage-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "\n",
            "Dataset downloaded. Unzipping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file\n",
        "!unzip -q garbage-classification.zip\n",
        "\n",
        "print(\"Dataset unzipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGCb6V4km55k",
        "outputId": "6f0de18f-35d9-41a1-e02b-e0fbea2f5782"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the \"Data Cleaning\" and \"Before vs. After\" Report\n",
        "# This is our version of \"handling missing values\" and \"removing duplicates\"\n",
        "# We will check if all images are readable.\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# This is the folder created by the zip file\n",
        "data_dir = 'Garbage classification/Garbage classification'\n",
        "classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "total_files_before = 0\n",
        "total_files_after = 0\n",
        "corrupted_files = 0\n",
        "class_counts = {}\n",
        "\n",
        "print(\"\\n--- Before vs. After Cleaning Report ---\")\n",
        "print(\"\\n[BEFORE]\")\n",
        "print(\"Source: garbage-classification.zip\")\n",
        "print(\"Status: 1 compressed file. Content unverified.\")\n",
        "\n",
        "print(\"\\n[AFTER]\")\n",
        "print(\"Status: Decompressed and verified all images.\")\n",
        "\n",
        "# Iterate over each class folder\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    image_files = os.listdir(class_dir)\n",
        "    class_counts[class_name] = 0\n",
        "\n",
        "    for image_file in image_files:\n",
        "        total_files_before += 1\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "\n",
        "        try:\n",
        "            # Try to open the image\n",
        "            with Image.open(image_path) as img:\n",
        "                img.verify() # Verify the image integrity\n",
        "\n",
        "            # If successful, count it\n",
        "            class_counts[class_name] += 1\n",
        "            total_files_after += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            # This is a \"missing\" or \"corrupted\" value\n",
        "            print(f\"Corrupted file found and skipped: {image_path} ({e})\")\n",
        "            corrupted_files += 1\n",
        "\n",
        "print(\"\\n--- Cleaning Summary ---\")\n",
        "print(f\"Total files found (Before): {total_files_before}\")\n",
        "print(f\"Corrupted files removed: {corrupted_files}\")\n",
        "print(f\"Total clean files (After): {total_files_after}\")\n",
        "\n",
        "print(\"\\nFinal Clean Dataset Distribution:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"- {class_name.title()}: {count} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOt-QSXnnC2K",
        "outputId": "39c1ad5a-aa91-4764-891a-09b3462faf54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Before vs. After Cleaning Report ---\n",
            "\n",
            "[BEFORE]\n",
            "Source: garbage-classification.zip\n",
            "Status: 1 compressed file. Content unverified.\n",
            "\n",
            "[AFTER]\n",
            "Status: Decompressed and verified all images.\n",
            "\n",
            "--- Cleaning Summary ---\n",
            "Total files found (Before): 2527\n",
            "Corrupted files removed: 0\n",
            "Total clean files (After): 2527\n",
            "\n",
            "Final Clean Dataset Distribution:\n",
            "- Cardboard: 403 images\n",
            "- Glass: 501 images\n",
            "- Metal: 410 images\n",
            "- Paper: 594 images\n",
            "- Plastic: 482 images\n",
            "- Trash: 137 images\n"
          ]
        }
      ]
    }
  ]
}